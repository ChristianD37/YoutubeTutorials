{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# or do it using pip from the command prompt\n",
    "import sys\n",
    "!{sys.executable} -m pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='deepseek-r1', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def ask_deepseek(input_content, system_prompt, deep_think = True, print_log = True):\n",
    "    response: ChatResponse = chat(model='deepseek-r1', messages=[\n",
    "        {'role' : 'system', 'content' : system_prompt},\n",
    "        {'role': 'user','content': input_content}\n",
    "    ])\n",
    "    response_text = response['message']['content']\n",
    "    if print_log: print(response_text)\n",
    "    # Extract everything inside <think>...</think> - this is the Deep Think\n",
    "    think_texts = re.findall(r'<think>(.*?)</think>', response_text, flags=re.DOTALL)\n",
    "    # Join extracted sections (optional, if multiple <think> sections exist)\n",
    "    think_texts = \"\\n\\n\".join(think_texts).strip()\n",
    "    # Exclude the Deep Think, and return the response\n",
    "    clean_response= re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Return either the context, or a tuple with the context and deep think\n",
    "    return clean_response if not deep_think else (clean_response, think_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "youtube_comments_df = pd.read_csv(r\"YOUR FILE PATH HERE\").head(10)\n",
    "youtube_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_sentiment = '''You will be provided with a youtube comment. Please rate the Youtube comment on a \n",
    "scale of -1 (very negative) to 1 (very positive) where 0 indicates neutral sentiment. Report the scores in increments of 0.1.\n",
    "Please only answer with the sentiment score and do not include any other word or explanation before or after the sentiment score.\n",
    "Do not include the '+' symbol in the output if the score is positive, but do inlcude the '-' symbol if the score is negative.\n",
    "Try your best to look out for humour and sarcasm. Some users may write comments that seem negative on the surface but\n",
    "are meant to be endearing. The distinction may not be that easy without the context of the video, but do your best!\n",
    "'''\n",
    "\n",
    "# Ask deepseek to score each comment and place the result in a new column\n",
    "#youtube_comments_df['LLM_SENTIMENT'] = youtube_comments_df['TEXT'].apply(lambda comment : ask_deepseek(comment, system_prompt_sentiment, deep_think=False))\n",
    "\n",
    "# Ask deepseek to score each comment, include the logic, and then place them both in a column\n",
    "youtube_comments_df[['LLM_SENTIMENT', 'LLM_DEEP_THINK']] = youtube_comments_df['TEXT'].apply(lambda comment : ask_deepseek(comment, system_prompt_sentiment)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df = pd.read_excel(r\"YOUR FILE PATH HERE\")\n",
    "pokemon_df = pokemon_df.head(9)\n",
    "pokemon_df\n",
    "\n",
    "pokemon_df['LLM_INPUT'] = pokemon_df.to_dict(orient='records')\n",
    "pokemon_df['LLM_INPUT'] = pokemon_df['LLM_INPUT'].astype(str)\n",
    "pokemon_df['LLM_INPUT'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_summary = \"\"\"Hi! I am building an app for designed around the popular pokemon games. The app is meant for users to scroll through\n",
    "each available Pokemon, and look through their various statistics and abilities. Your job is take in an individual Pokemon's data in the form\n",
    "of a JSON format. From there, I'd like you to write a 3-5 sentence summary about the Pokemon's battle capabilities. Please address\n",
    "what might be their strengths and weaknesses? Thank you! The output should be a string that formatted as a paragraph that should not exceed\n",
    "five sentences. Reminder that these stats refer to the Pokemon video games, and not the cards or TV show.\n",
    "\n",
    "Keep in mind a few things regarding the structure of the input.\n",
    "\n",
    "+ The name and identifier of the pokemon is in the 'name' field.\n",
    "+ The main statistics for pokemon battling are in the 'Attack', 'Defense', 'Sp. Atk', 'Sp. Def', 'Speed' fields\n",
    "+ If a pokemon has a mega evolution denoted in the 'has_mega_evolution' column, then it is worth pointing out\n",
    "+ The 'evolution' field refers to Pokemon that it evolves into, and should not be confused with the Pokemon currently of interest.\n",
    "\"\"\"\n",
    "# Ask deepseek to summarize each pokemon's data, include the logic, and then place them both in a column\n",
    "pokemon_df[['LLM_SUMMARY', 'LLM_DEEP_THINK']] =pokemon_df['LLM_INPUT'].apply(lambda data : ask_deepseek(data, system_prompt_summary)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon_df\n",
    "print(pokemon_df['LLM_SUMMARY'][6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraper_tutorial_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
